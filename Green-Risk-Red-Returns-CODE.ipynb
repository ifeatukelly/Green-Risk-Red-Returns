{
 "cells": [
  {
   "cell_type": "raw",
   "id": "84766e37-b8ab-438b-b80a-f341b4977f6d",
   "metadata": {},
   "source": [
    "########### RETRIEVING ANNUAL FINANCIAL DATA ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07d81de-c30f-4419-aa1e-b2f25da4f809",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import yfinance as yf\n",
    "import pandas as pd\n",
    "import eikon as ek\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ea4d4b1-3400-4af2-abbb-f13246531dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of company ticker (compatitable with EIKON)\n",
    "tickers_eikon = [\n",
    "    \"1605.T\", \"1928.T\", \"4063.T\", \"4091.T\", \"4503.T\", \"4568.T\", \"4578.T\", \"4612.T\", \n",
    "    \"4661.T\", \"5020.T\", \"6098.T\", \"6301.T\", \"6367.T\", \"6501.T\", \"6594.T\", \"6861.T\",\n",
    "    \"6954.T\", \"6971.T\", \"6981.T\", \"7741.T\", \"8002.T\", \"8015.T\", \"8031.T\", \"8035.T\",\n",
    "    \"8053.T\", \"8630.T\", \"8830.T\", \"9020.T\", \"9022.T\", \"9101.T\", \"7203.T\", \"8306.T\",\n",
    "    \"8316.T\", \"6758.T\", \"7203.T\", \"000100.KS\", \"000270.KS\", \"000660.KS\", \"001040.KS\", \n",
    "    \"003495.KS\", \"003670.KS\", \"005930.KS\", \"010130.KS\", \"010950.KS\", \"011200.KS\", \n",
    "    \"012330.KS\", \"012450.KS\", \"020560.KS\", \"021240.KS\", \"024110.KS\", \"034020.KS\", \n",
    "    \"035250.KS\", \"035420.KS\", \"035720.KS\", \"036460.KS\", \"047810.KS\", \"068270.KS\", \n",
    "    \"086790.KS\", \"096775.KS\", \"196170.KQ\", \"207940.KS\", \"241560.KS\", \"259960.KS\",\n",
    "    \"005380.KS\", \"105560.KS\", \"015760.KS\", \"005490.KS\", \"055550.KS\", \"017670.KS\",\n",
    "    \"316140.KS\", \"SEAT.SI\", \"CAPD.SI\", \"SINA.SI\", \"IFAS.SI\", \"RVHL.SI\", \"WLIL.SI\",\n",
    "    \"FRAE.SI\", \"JCYC.SI\", \"CTDM.SI\", \"CMLT.SI\", \"CMDG.SI\", \"SIAL.SI\", \"NETL.SI\", \n",
    "    \"DBSM.SI\", \"GAGR.SI\", \"GENS.SI\", \"CAPS.SI\", \"KASA.SI\", \"MAPI.SI\", \"HPHT.SI\", \n",
    "    \"OCBC.SI\", \"SHEN.SI\", \"STEG.SI\", \"PARA.SI\", \"SUNT.SI\", \"HPAR.SI\", \"SIND.SI\", \n",
    "    \"UOBH.SI\", \"UTOS.SI\", \"SCIL.SI\", \"VENM.SI\", \"OLAG.SI\", \"SPOS.SI\", \"YNLG.SI\", \n",
    "    \"STEL.SI\", \"ABB.NS\", \"ADNA.NS\", \"APSE.NS\", \"ADAN.NS\", \"ABUJ.NS\", \"ADAG.NS\", \n",
    "    \"BAJE.NS\", \"CGPO.NS\", \"COAL.NS\", \"DLF.NS\", \"EICH.NS\", \"GAIL.NS\", \"GOCP.NS\", \n",
    "    \"GRAS.NS\", \"HIAE.NS\", \"HDBK.NS\", \"IHTL.NS\", \"INGL.NS\", \"IOC.NS\", \"JNSP.NS\", \n",
    "    \"JSWE.NS\", \"LART.NS\", \"LUPN.NS\", \"MAHM.NS\", \"MRTI.NS\", \"NTPC.NS\", \"OEBO.NS\", \n",
    "    \"ONGC.NS\", \"PGRD.NS\", \"RELI.NS\", \"SHCM.NS\", \"SUN.NS\", \"TCS.NS\", \"ULTC.NS\", \n",
    "    \"VDAN.NS\", \"AOT.BK\", \"BA.BK\", \"BANPU.BK\", \"BBL.BK\", \"BCT.BK\", \"BDMS.BK\", \n",
    "    \"BEM.BK\", \"BGRIM.BK\", \"BJC.BK\", \"BTS.BK\", \"CENTEL.BK\", \"CPALL.BK\", \"CPF.BK\", \n",
    "    \"CPN.BK\", \"DELTA.BK\", \"EA.BK\", \"EGCO.BK\", \"GPSC.BK\", \"GULF.BK\", \"INTUCH.BK\", \n",
    "    \"IVL.BK\", \"KBANK.BK\", \"KTB.BK\", \"KTC.BK\", \"LH.BK\", \"MINT.BK\", \"PTTEP.BK\", \n",
    "    \"PTT_n.BK\", \"RATCH.BK\", \"SCC.BK\", \"TISCO.BK\", \"TOP.BK\", \"TRUE.BK\", \"TTB.BK\", \n",
    "    \"WHA.BK\", \"000333.SZ\", \"000651.SZ\", \"000725.SZ\", \"002352.SZ\", \"002415.SZ\", \n",
    "    \"002475.SZ\", \"002594.SZ\", \"0267.HK\", \"0390.HK\", \"0788.HK\", \"0857.HK\", \"0883.HK\", \n",
    "    \"1398.HK\", \"1766.HK\", \"300124.SZ\", \"300274.SZ\", \"600028.SS\", \"600104.SS\", \n",
    "    \"600276.SS\", \"600309.SS\", \"600900.SS\", \"601012.SS\", \"601088.SS\", \"601111.SS\", \n",
    "    \"601127.SS\", \"601628.SS\", \"601633.SS\", \"601668.SS\", \"601800.SS\", \"601899.SS\", \n",
    "    \"601919.SS\", \"0241.HK\", \"600519.SS\", \"601288.SS\", \"0700.HK\"\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78764b12-1860-4ecf-ab75-20eb8855040f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set your Eikon API key - DO NOT FORGOT TO HIDE API KEY WHEN SHARING!\n",
    "ek.set_app_key('insert_your_API_key')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b11742f-efea-42c8-aae2-0d4ac1212910",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the data items we want to retrieve\n",
    "fields = ['TR.TotalAssets', 'TR.TotalEquity']\n",
    "\n",
    "# Set the date range\n",
    "start_date = '2019-01-01'\n",
    "end_date = '2024-01-01'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c20247c9-d181-4ba3-8690-47ec86465e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the data\n",
    "data, err = ek.get_data(instruments=tickers_eikon,\n",
    "                        fields=fields,\n",
    "                        parameters={\n",
    "                            'SDate': start_date,\n",
    "                            'EDate': end_date,\n",
    "                            'FRQ': 'FY'  # Annual frequency\n",
    "                        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe28dcea-6951-4181-8c8a-d9dd3ba0674f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the data to a more usable format\n",
    "df = pd.DataFrame(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d403177d-739b-4ffb-85e7-117fd6c7f01d",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)\n",
    "\n",
    "# As we can see, there is no 'date' column..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c08b79-7b32-483b-9ff4-e5121de9a836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve annual data using `ek.get_timeseries` (with Date column)\n",
    "# THIS TAKES AROUND 2 MINUTES TO RUN\n",
    "dfs = []\n",
    "for company in tickers_eikon:\n",
    "    try:\n",
    "        annual_financials = ek.get_timeseries(company, fields=fields, start_date=start_date, end_date=end_date, interval='yearly')\n",
    "        annual_financials['Company'] = company\n",
    "        dfs.append(annual_financials)\n",
    "    except Exception as e:\n",
    "        print(f\"Error retrieving data for {company}: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5517a096-592a-438c-b955-6d3a1231723e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all data into a single DataFrame\n",
    "if dfs:\n",
    "    annual_financials = pd.concat(dfs).reset_index()\n",
    "    print(annual_financials)\n",
    "else:\n",
    "    print(\"No data retrieved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a74c001-0974-43de-bbee-d53b034a51c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns in the new DataFrame to be identical with the previous one\n",
    "annual_financials.rename(columns={\n",
    "    'TR.TOTALASSETS': 'Total Assets',\n",
    "    'TR.TOTALEQUITY': 'Total Equity'\n",
    "    }, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f552c53-3ff1-47bf-b61a-4db8b787c7d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated DataFrame\n",
    "print(annual_financials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f749ca21-2bbf-4f8d-b16a-980e5d21fe80",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace values in df with values from annual_financials\n",
    "annual_financials['Total Assets'] = df['Total Assets'].values\n",
    "annual_financials['Total Equity'] = df['Total Equity'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98691423-37c3-4dea-8776-e7b40fbf64a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated DataFrame\n",
    "print(annual_financials.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1022b2d0-f3f4-4ef6-a6bf-c77c4444fdb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert column to label the year\n",
    "annual_financials['Date'] = pd.to_datetime(annual_financials['Date'])\n",
    "\n",
    "annual_financials['Year'] = annual_financials['Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6764211f-3400-4bad-af77-8437fb75bb5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert column for the financial leverage equation\n",
    "annual_financials['Financial Leverage'] = annual_financials['Total Assets'] / annual_financials['Total Equity']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd662a6-86b9-4312-be55-7a68b6700ec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder the columns in the desired order\n",
    "annual_financials = annual_financials[['Date', 'Year', 'Company', 'Total Assets', 'Total Equity', 'Financial Leverage']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cfefb5e-6628-4d13-9862-b4b5682c0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column names\n",
    "annual_financials.columns = annual_financials.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b17237c-30c4-4fb8-8016-95da3de250b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the updated DataFrame\n",
    "print(annual_financials)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad08527-cf48-4c78-aef7-2a5ce6e3dc92",
   "metadata": {},
   "source": [
    "########### RETRIEVING STOCK CHARACTERISTICS ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7444c54c-2b78-4dbc-8fd0-f31eb3c9ffc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a list of company tickers (compatible with Yahoo Finance)\n",
    "# All of the companies are the same and in the same order as the previous ticker list...\n",
    "# The ticker names have just been changed for compatability\n",
    "tickers = [\n",
    "    \"1605.T\", \"1928.T\", \"4063.T\", \"4091.T\", \"4503.T\", \"4568.T\", \"4578.T\",\n",
    "    \"4612.T\", \"4661.T\", \"5020.T\", \"6098.T\", \"6301.T\", \"6367.T\", \"6501.T\", \n",
    "    \"6594.T\", \"6861.T\", \"6954.T\", \"6971.T\", \"6981.T\", \"7741.T\", \"8002.T\", \n",
    "    \"8015.T\", \"8031.T\", \"8035.T\", \"8053.T\", \"8630.T\", \"8830.T\", \"9020.T\",\n",
    "    \"9022.T\", \"9101.T\", \"HMC\", \"MUFG\", \"SMFG\", \"SONY\", \"TM\", \"000100.KS\",\n",
    "    \"000270.KS\", \"000660.KS\", \"001040.KS\", \"003495.KS\", \"003670.KS\", \"005930.KS\",\n",
    "    \"010130.KS\", \"010950.KS\", \"011200.KS\", \"012330.KS\", \"012450.KS\", \"020560.KS\",\n",
    "    \"021240.KS\", \"024110.KS\", \"034020.KS\", \"035250.KS\", \"035420.KS\", \"035720.KS\",\n",
    "    \"036460.KS\", \"047810.KS\", \"068270.KS\", \"086790.KS\", \"096775.KS\", \"196170.KQ\",\n",
    "    \"207940.KS\", \"241560.KS\", \"259960.KS\", \"HYMTF\", \"KB\", \"KEP\", \"PKX\", \n",
    "    \"SHG\", \"SKM\", \"WF\", \"5E2.SI\", \"A17U.SI\", \"A26.SI\", \"AIY.SI\", \"AP4.SI\",\n",
    "    \"F34.SI\", \"BUOU.SI\", \"C07.SI\", \"C09.SI\", \"C38U.SI\", \"C52.SI\", \"C6L.SI\", \n",
    "    \"CJLU.SI\", \"D05.SI\", \"E5H.SI\", \"G13.SI\", \"HMN.SI\", \"K71U.SI\", \n",
    "    \"ME8U.SI\", \"NS8U.SI\", \"O39.SI\", \"OV8.SI\", \"S63.SI\", \"SK6U.SI\",\n",
    "    \"T82U.SI\", \"H02.SI\", \"U06.SI\", \"U11.SI\", \"U14.SI\", \"U96.SI\", \"V03.SI\", \"VC2.SI\",\n",
    "    \"S08.SI\", \"Z25.SI\", \"Z74.SI\", \"ABB.NS\", \"ADANIGREEN.NS\", \"ADANIPORTS.NS\", \"ADANIPOWER.NS\",\n",
    "    \"AMBUJACEM.NS\", \"ATGL.NS\", \"BEL.NS\", \"CGPOWER.NS\", \"COALINDIA.NS\", \"DLF.NS\",\n",
    "    \"EICHERMOT.NS\", \"GAIL.NS\", \"GODREJPROP.NS\", \"GRASIM.NS\", \"HAL.NS\", \"HDB\",\n",
    "    \"INDHOTEL.NS\", \"INDIGO.NS\", \"IOC.NS\", \"JINDALSTEL.NS\", \"JSWENERGY.NS\", \"LT.NS\",\n",
    "    \"LUPIN.NS\", \"M&M.NS\", \"MARUTI.NS\", \"NTPC.NS\", \"OBEROIRLTY.NS\", \"ONGC.NS\",\n",
    "    \"POWERGRID.NS\", \"RELIANCE.NS\", \"SHREECEM.NS\", \"SUNPHARMA.NS\", \"TCS.NS\",\n",
    "    \"ULTRACEMCO.NS\", \"VEDL.NS\", \"AOT.BK\", \"BA.BK\", \"BANPU.BK\", \"BBL.BK\", \"BCT.BK\",\n",
    "    \"BDMS.BK\", \"BEM.BK\", \"BGRIM.BK\", \"BJC.BK\", \"BTS.BK\", \"CENTEL.BK\", \"CPALL.BK\",\n",
    "    \"CPF.BK\", \"CPN.BK\", \"DELTA.BK\", \"EA.BK\", \"EGCO.BK\", \"GPSC.BK\", \"GULF.BK\",\n",
    "    \"INTUCH.BK\", \"IVL.BK\", \"KBANK.BK\", \"KTB.BK\", \"KTC.BK\", \"LH.BK\", \"MINT.BK\",\n",
    "    \"PTTEP.BK\", \"PTT-R.BK\", \"RATCH.BK\", \"SCC.BK\", \"TISCO.BK\", \"TOP.BK\", \"TRUE.BK\",\n",
    "    \"TTB.BK\", \"WHA.BK\", \"000333.SZ\", \"000651.SZ\", \"000725.SZ\", \"002352.SZ\", \n",
    "    \"002415.SZ\", \"002475.SZ\", \"002594.SZ\", \"0267.HK\", \"0390.HK\", \"0788.HK\",\n",
    "    \"0857.HK\", \"0883.HK\", \"1398.HK\", \"1766.HK\", \"300124.SZ\", \"300274.SZ\",\n",
    "    \"600028.SS\", \"600104.SS\", \"600276.SS\", \"600309.SS\", \"600900.SS\", \"601012.SS\",\n",
    "    \"601088.SS\", \"601111.SS\", \"601127.SS\", \"601628.SS\", \"601633.SS\", \"601668.SS\",\n",
    "    \"601800.SS\", \"601899.SS\", \"601919.SS\", \"BABA\", \"600519.SS\", \"601288.SS\", \"TCEHY\"\n",
    "           ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "727cb607-da19-41dc-b754-33c527068a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set date range\n",
    "start_date = datetime(2019, 1, 1)\n",
    "end_date = datetime(2023, 12, 31)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe2898d-4fe4-49f2-9bfe-85017cac2c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the data\n",
    "data_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65715618-b7fd-4747-b53d-3a4ab58dcecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES ABOUT TWO MINUTES TO RUN \n",
    "for ticker in tickers:\n",
    "    # Download stock data\n",
    "    stock = yf.Ticker(ticker)\n",
    "    hist = stock.history(start=start_date, end=end_date)\n",
    "    \n",
    "    # Get company info\n",
    "    info = stock.info\n",
    "    industry = info.get('industry', 'N/A')\n",
    "    sector = info.get('sector', 'N/A')\n",
    "    market_cap = info.get('marketCap', 'N/A')\n",
    "    \n",
    "    # Process the data\n",
    "    for date, row in hist.iterrows():\n",
    "        data_list.append({\n",
    "            'date': date.strftime('%Y-%m-%d'),\n",
    "            'year': date.year,\n",
    "            'company': ticker,\n",
    "            'close': row['Close'],\n",
    "            'volume': row['Volume'],\n",
    "            'market_capitalisation' : market_cap,\n",
    "            'industry': industry,\n",
    "            'sector': sector\n",
    "        })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aebed7c-dbcb-4943-9709-1175163ae6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame from the list\n",
    "result = pd.DataFrame(data_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dcd4922-5710-4898-825a-0a106d9a047a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the result\n",
    "print(result.head(20))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bacf2756-90c8-4abe-9c0b-fd363e8c01b7",
   "metadata": {},
   "source": [
    "########### CONVERT TO ANNUAL MARKET CAPITALISATION ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3df506bc-7959-4082-a377-b8f14682c47b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the 'date' column to datetime\n",
    "result['date'] = pd.to_datetime(result['date'])\n",
    "\n",
    "# Set 'date' as the index\n",
    "result.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e11cc75-b207-43c8-89be-36b736de1120",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by company and resample to yearly frequency, taking the last market cap of each year\n",
    "annual_marketcap = result.groupby('company').resample('Y')['market_capitalisation'].last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b2da012-1507-48b7-a5c9-e8956f28e351",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from the date\n",
    "annual_marketcap['year'] = annual_marketcap['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d7cf3f-872f-4032-aecc-a33f301532c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to match the desired output\n",
    "annual_marketcap = annual_marketcap[['year', 'company', 'market_capitalisation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3230bf55-2ce9-4f25-9d5d-8c7c9cc945e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index if needed\n",
    "annual_marketcap.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff527676-c4d7-4d6a-b4f6-ae931537efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge annual_marketcap with annual_financials\n",
    "annual_financials = annual_financials.merge(annual_marketcap, on=['year', 'company'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5688e3-a38c-4990-b21a-1cd70c80f7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the updated annual_financials DataFrame\n",
    "print(annual_financials.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5570782d-1881-467f-976c-448344a22962",
   "metadata": {},
   "source": [
    "########### CONVERT TO MONTHLY RETURNS ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73bf11cc-f2b2-4ecb-8c19-532ca400451e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by company and resample to monthly frequency, taking the last price of each month\n",
    "monthly_prices = result.groupby('company').resample('M')['close'].last().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d33e2c9-0816-4673-8811-a13fb83626d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year from the date\n",
    "monthly_prices['year'] = monthly_prices['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93a6c9e2-841b-4790-907e-24e766d96ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reorder columns to match the desired output\n",
    "monthly_prices = monthly_prices[['date', 'year', 'company', 'close']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5facda44-5aa9-4de6-a073-504ad6fecc26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "monthly_prices.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b81a6df1-4e34-4f8e-9ac3-e01b63846cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the new DataFrame\n",
    "print(monthly_prices.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa53128-0f10-4034-a98e-de9b2ac2fea0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary library \n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d967a7-89c6-466e-8227-2105d2598bb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure 'date' is set as the index\n",
    "monthly_prices.set_index('date', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b9f5545-e02c-40d2-89e8-60fe7a1511bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by company and date\n",
    "monthly_prices = monthly_prices.sort_values(['company', 'date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdc7aec1-637f-4c36-b36b-5205aa1f3d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate returns\n",
    "monthly_prices['returns'] = monthly_prices.groupby('company')['close'].transform(lambda x: np.log(x) - np.log(x.shift(1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e207c730-9dce-48bc-9023-f0cfd17c0eda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "monthly_prices.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b35ccf1b-fdc4-4d6f-8164-5ee49e49e7a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a new DataFrame for monthly returns\n",
    "monthly_returns = monthly_prices[['date', 'year', 'company', 'returns']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c10acc86-9261-4b65-91a4-39f7ba060a67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove the first row for each company (which will have NaN return)\n",
    "monthly_returns = monthly_returns.groupby('company').apply(lambda x: x.iloc[1:]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de08c523-e573-4233-9d9e-6994fbe3de8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the new DataFrame\n",
    "print(monthly_returns.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b87cfcf-8998-4b80-a3cf-8006804ad522",
   "metadata": {},
   "source": [
    "########### RETRIEVING COMPANY HQ ADDRESS ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca1adf3e-5e34-4ab6-9c8d-25a170fa8b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Downloading the HQ Data for all of the tickers\n",
    "def get_company_hq(ticker):\n",
    "    try:\n",
    "        stock = yf.Ticker(ticker)\n",
    "        info = stock.info\n",
    "        if 'city' in info and 'state' in info and 'country' in info:\n",
    "            return f\"{info['city']}, {info['state']}, {info['country']}\"\n",
    "        elif 'city' in info and 'country' in info:\n",
    "            return f\"{info['city']}, {info['country']}\"\n",
    "        else:\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data for {ticker}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dd8e05c-0cd5-40a3-bd92-4ead18755da9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch HQ Address for each company\n",
    "hq_list = []\n",
    "for ticker in tickers:\n",
    "    hq_address = get_company_hq(ticker)\n",
    "    hq_list.append({\"Ticker\": ticker, \"HQ Address\": hq_address})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "956896da-ae04-4bdb-aa0b-3200595937a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to DataFrame\n",
    "df1 = pd.DataFrame(hq_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7baa3ccc-6f3e-4687-87a3-4c3267ecfdfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split HQ Address into City and Country\n",
    "def split_hq_address(hq_address):\n",
    "    if hq_address:\n",
    "        parts = hq_address.split(', ')\n",
    "        city = parts[0]\n",
    "        country = parts[-1]  # Assuming the country is always the last part\n",
    "        return city, country\n",
    "    return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a417722-fcd8-46bd-adcc-6eddaf9543e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply the function to split the HQ Address into City and Country columns\n",
    "df1['City'], df1['Country'] = zip(*df1['HQ Address'].apply(split_hq_address))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbe8226d-2245-43e6-a54d-5e07ef5bffbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output the dataframe with additional columns\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0ee696-cab1-4f46-81ba-2799f8016a8c",
   "metadata": {},
   "source": [
    "########### RETRIEVING LATITUDE AND LONGITUDE ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47963c7-a78f-4ade-845f-8f37734a2295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.exc import GeocoderTimedOut\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54396bae-916a-4cdc-a0b6-eb99570492b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialise Nominatim API\n",
    "geolocator = Nominatim(user_agent=\"MyApp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b3ca4ac-19d0-4fab-a059-9806d37ec382",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get latitude and longitude from a city name with timeout\n",
    "def get_lat_lon(city):\n",
    "    try:\n",
    "        location = geolocator.geocode(city, timeout=10)  # Add a timeout of 10 seconds\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        else:\n",
    "            print(f\"Location not found for: {city}\")\n",
    "            return None, None\n",
    "    except GeocoderTimedOut:\n",
    "        print(f\"Timeout occurred for: {city}\")\n",
    "        return None, None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching geolocation for {city}: {e}\")\n",
    "        return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9532233-dc3d-4548-ab1e-e46ca3de762f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lists to store latitude and longitude\n",
    "latitudes = []\n",
    "longitudes = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8f04f15-035a-45b5-a329-3fce9e69f541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKE AROUND 4 MINUTES TO RUN\n",
    "# Loop through the DataFrame to get lat/lon\n",
    "for index, row in df1.iterrows():\n",
    "    city = row['City']\n",
    "    print(f\"Processing city: {city}\")  # Log progress\n",
    "    lat, lon = get_lat_lon(city)  # Use only the City column\n",
    "    latitudes.append(lat)\n",
    "    longitudes.append(lon)\n",
    "    time.sleep(1)  # Add 1-second delay between requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4f95e28-07ed-4e49-be8d-98476ae70c2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the latitudes and longitudes to the DataFrame\n",
    "df1['Latitude'] = latitudes\n",
    "df1['Longitude'] = longitudes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed819d30-a1c3-484a-9571-606c7bc29bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the updated DataFrame\n",
    "df1.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6028cbb-1c23-43e0-9641-a045a5fe85c1",
   "metadata": {},
   "source": [
    "########### RETRIEVING ACTUAL WEATHER DATA ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b42e5f5-93c3-40d4-ad53-1133cea60fcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "from retry_requests import retry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62e325b-578c-428b-8cc3-0f7b869ffc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the Open-Meteo API client with caching and retries\n",
    "cache_session = requests_cache.CachedSession('.cache', expire_after=-1)\n",
    "retry_session = retry(cache_session, retries=5, backoff_factor=0.2)\n",
    "openmeteo = openmeteo_requests.Client(session=retry_session)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359d2e76-9032-40e8-9ff3-8b1d1b384490",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the date range for historical weather data\n",
    "start_date = \"2019-01-01\"\n",
    "end_date = \"2023-12-31\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca52178-6480-49d6-8d75-1c303bc3b9be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a list to store the results\n",
    "weather_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00acd73-7204-42a9-865b-2e314f444274",
   "metadata": {},
   "outputs": [],
   "source": [
    "# THIS TAKES AROUND TWO MINUTES TO RUN\n",
    "# Loop through each row in the DataFrame\n",
    "for index, row in df1.iterrows():\n",
    "    ticker = row['Ticker']\n",
    "    city = row['City']\n",
    "    country = row['Country']\n",
    "    latitude = row['Latitude']\n",
    "    longitude = row['Longitude']\n",
    "    \n",
    "    if pd.notna(latitude) and pd.notna(longitude):  # Ensure valid latitude and longitude\n",
    "        print(f\"Fetching data for Ticker: {ticker}, City: {city}, Country: {country}\")\n",
    "\n",
    "        # Set API parameters for the current location\n",
    "        url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "        params = {\n",
    "            \"latitude\": latitude,\n",
    "            \"longitude\": longitude,\n",
    "            \"start_date\": start_date,\n",
    "            \"end_date\": end_date,\n",
    "            \"daily\": \"temperature_2m_max\", \n",
    "            \"timezone\": \"auto\"\n",
    "        }\n",
    "\n",
    "        try:\n",
    "            # Fetch the weather data for the current location\n",
    "            responses = openmeteo.weather_api(url, params=params)\n",
    "            response = responses[0]\n",
    "            \n",
    "            # Extract daily weather data\n",
    "            daily = response.Daily()\n",
    "            daily_temperature_2m_max = daily.Variables(0).ValuesAsNumpy()\n",
    "            \n",
    "            # Create a dictionary for each date\n",
    "            daily_dates = pd.date_range(\n",
    "                start=pd.to_datetime(daily.Time(), unit=\"s\", utc=True),\n",
    "                end=pd.to_datetime(daily.TimeEnd(), unit=\"s\", utc=True),\n",
    "                freq=pd.Timedelta(seconds=daily.Interval()),\n",
    "                inclusive=\"left\"\n",
    "            )\n",
    "            \n",
    "            for i, date in enumerate(daily_dates):\n",
    "                weather_data.append({\n",
    "                    \"Ticker\": ticker,\n",
    "                    \"City\": city,\n",
    "                    \"Country\": country,\n",
    "                    \"Latitude\": latitude,\n",
    "                    \"Longitude\": longitude,\n",
    "                    \"Date\": date,\n",
    "                    \"Temperature_Max\": daily_temperature_2m_max[i],\n",
    "                })\n",
    "\n",
    "        except Exception as e:\n",
    "            print(f\"Error fetching data for {ticker} ({city}, {country}): {e}\")\n",
    "\n",
    "        time.sleep(0.5) # To prevent breaking API limit use"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3aec6d-7452-4f97-9191-7240f2c0655f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the list of dictionaries to a DataFrame\n",
    "weather_df = pd.DataFrame(weather_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8eae834-82e7-4eca-8ff9-96c8fecfcf1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame by Ticker and Date for panel structure\n",
    "weather_df = weather_df.sort_values(by=[\"Ticker\", \"Date\"]).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6637e14b-3d81-4f54-9169-0dd034ec0cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert column names\n",
    "weather_df.columns = weather_df.columns.str.lower().str.replace(' ', '_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df648a90-4c0d-43a5-8281-9d3d93c96a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename column name\n",
    "weather_df = weather_df.rename(columns={'ticker': 'company'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a3d2d92-b027-4c1c-ae65-539b16b7aa2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the weather DataFrame\n",
    "weather_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb0409b5-5278-49b8-a147-61d05ee137aa",
   "metadata": {},
   "source": [
    "########### IDENTIFY EXTREME DAYS PER MONTH ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6535e63b-1a08-43ef-849b-73d26a902253",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'extreme' column\n",
    "weather_df['extreme'] = ((weather_df['temperature_max'] > 30) | (weather_df['temperature_max'] < 0)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "955a6a47-36ca-49c4-aa1f-51f5bfe76c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'date' to datetime\n",
    "weather_df['date'] = pd.to_datetime(weather_df['date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38797f53-c395-435e-8522-1e890964b28b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract year and month from the Date\n",
    "weather_df['year'] = weather_df['date'].dt.year\n",
    "weather_df['month'] = weather_df['date'].dt.month"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c80df2e-8c51-4c56-9d2e-0a06eb6543b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by Company, Year, and Month, then sum the 'extreme' column\n",
    "extreme_days_df = weather_df.groupby(['company', 'year', 'month'])['extreme'].sum().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8728555-84a5-4b46-a3bf-d1b978146d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename the sum column to 'extreme_days'\n",
    "extreme_days_df = extreme_days_df.rename(columns={'extreme': 'extreme_days'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3097ffb3-1d0d-4ca6-8941-a6614874ef07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort the DataFrame\n",
    "extreme_days_df = extreme_days_df.sort_values(['company', 'year', 'month'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf082a-0112-4b80-bbfa-5b6bca7f7139",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the new DataFrame\n",
    "print(extreme_days_df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5776bf4-c310-4239-bdfb-6f97c6c727ca",
   "metadata": {},
   "source": [
    "########### CREATION OF SQL DATABASE ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9f992e7-985e-4773-85b9-f3867e3c43ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required library\n",
    "import sqlite3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5dd5771-3c62-41c1-ae93-0de0e87f30e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a connection to the SQLite database (it will create the database if it doesn't exist)\n",
    "con = sqlite3.connect('ICM406_database_trial2.db')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a922208-96c3-4014-abde-9a3870f6bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a cursor object to interact with the database\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0d26fd2-ce66-4f9f-84c2-7395656a22f4",
   "metadata": {},
   "source": [
    "####### Annual Financial Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f998c5-d461-405f-ae57-18dcb5ab5bf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the Financials table to store the financial data\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS Financials (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        date DATE NOT NULL,\n",
    "        year INTEGER NOT NULL,\n",
    "        company TEXT NOT NULL,\n",
    "        total_assets REAL,\n",
    "        total_equity REAL,\n",
    "        financial_leverage REAL,\n",
    "        market_capitalisation INTEGER\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75645b0-cbb5-4b7a-9692-0d857bd4cee7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data from the DataFrame into the Financials table\n",
    "annual_financials.to_sql('Financials', con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d9bf9a-4bc4-42e5-a363-e1ed6abc9b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the transaction\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab4462b-0f51-4c30-b3eb-1eaddfe8afa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data by querying the database\n",
    "query_result_financials = pd.read_sql_query(\"SELECT * FROM Financials\", con)\n",
    "print(query_result_financials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd725a83-583e-49a6-9876-69d3b8abd5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Summary Stats of Financials table\n",
    "\n",
    "# Define the columns you want to analyze\n",
    "columns_to_analyse = ['financial_leverage', 'market_capitalisation']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8aa657e-23d6-47a6-8dec-1bc4ed57eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store results\n",
    "financials_analysis = []\n",
    "\n",
    "for column in columns_to_analyse:\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        '{column}' AS column_name,\n",
    "        AVG({column}) AS mean,\n",
    "        MIN({column}) AS min,\n",
    "        MAX({column}) AS max,\n",
    "        SUM({column}) AS sum,\n",
    "        AVG({column} * {column}) - AVG({column}) * AVG({column}) AS variance\n",
    "    FROM Financials\n",
    "    WHERE {column} IS NOT NULL\n",
    "    \"\"\"\n",
    "\n",
    "    df2 = pd.read_sql_query(query, con)\n",
    "    df2['std_dev'] = np.sqrt(df2['variance'])\n",
    "    financials_analysis.append(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91e33d90-5502-4f8c-82c2-320b7dd3c65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "financials_results = pd.concat(financials_analysis, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b0869a-4119-48cf-b9e7-77db42283c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "print(financials_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8bc189d-fd2b-4acb-ab6e-4373e159613c",
   "metadata": {},
   "source": [
    "####### Stock Characteristics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034c590-0ef6-4bf3-b00b-9eed4ba005f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the StockData table to store stock data\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS StockData (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        year INTEGER,\n",
    "        company TEXT NOT NULL,\n",
    "        close REAL,\n",
    "        volume INTEGER\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ad35cb0-0808-4449-b2c9-94569887b008",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove Unecessary Columns\n",
    "result1 = result.drop(['sector', 'industry', 'market_capitalisation'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5dbe49-8555-4d5d-beac-ff41ac855407",
   "metadata": {},
   "outputs": [],
   "source": [
    "result1 = result1.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98e577d1-5d96-4924-8e98-0e539152fc32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data from the DataFrame into the StockData table\n",
    "result1.to_sql('StockData', con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba15b9b-152e-4f29-8f5a-48ebc22fcb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the transaction\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f08b408-b8f0-40c6-b564-fd88b67037fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data by querying the StockData table\n",
    "query_result_stockdata = pd.read_sql_query(\"SELECT * FROM StockData\", con)\n",
    "print(query_result_stockdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e58c88-867c-49f1-8253-4919ca1ec64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Summary Stats of the StockData Table\n",
    "\n",
    "# Define the columns you want to analyze\n",
    "columns_to_analyse1 = ['close', 'volume']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c68da48-a826-4c3c-8919-63c647e95d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store results\n",
    "stockdata_analysis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea288a1d-51a3-44c1-b55d-c0d10544819c",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_analyse1:\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        '{column}' AS column_name,\n",
    "        AVG({column}) AS mean,\n",
    "        MIN({column}) AS min,\n",
    "        MAX({column}) AS max,\n",
    "        SUM({column}) AS sum,\n",
    "        AVG({column} * {column}) - AVG({column}) * AVG({column}) AS variance\n",
    "    FROM StockData\n",
    "    WHERE {column} IS NOT NULL\n",
    "    \"\"\"\n",
    "\n",
    "    df3 = pd.read_sql_query(query, con)\n",
    "    df3['std_dev'] = np.sqrt(df3['variance'])\n",
    "    stockdata_analysis.append(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce324bc0-ae52-439c-8f6d-c45a55352f7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "stockdata_results = pd.concat(stockdata_analysis, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fd042c1-2c4b-4285-ac08-0ac00f31a5cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "print(stockdata_results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8e45dd-b8ad-47bd-b3cb-ce69713c1c6c",
   "metadata": {},
   "source": [
    "####### Company Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9208817d-ea80-4eae-8203-a171ebf0d91c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the CompanyData table to store company data\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS CompanyData (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        company TEXT NOT NULL,\n",
    "        country TEXT NOT NULL,\n",
    "        city TEXT NOT NULL,\n",
    "        latitude REAL,\n",
    "        longitude REAL\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9becd6-488d-432d-bab2-ee8152b4aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "company_data = weather_df[['company', 'city', 'country', 'latitude', 'longitude']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d3281d3-0675-4242-b5c1-2821ebd70a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data from the DataFrame into the CompanyData table\n",
    "company_data.to_sql('CompanyData', con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a872d1-c672-4119-a6dc-35061aa6b55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the transaction\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0caf59d4-9d21-4f6e-a29a-7fcae07c35d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data by querying the CompanyData table\n",
    "query_result_companydata = pd.read_sql_query(\"SELECT * FROM CompanyData\", con)\n",
    "print(query_result_companydata)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd949ff0-edaa-44f6-8ee3-42a7b2b8892d",
   "metadata": {},
   "source": [
    "####### Weather"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a0f56e3-f968-457b-8dae-c966fc443d06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the WeatherData table to store weather data\n",
    "cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS WeatherData (\n",
    "        id INTEGER PRIMARY KEY AUTOINCREMENT,\n",
    "        date DATE NOT NULL,\n",
    "        company TEXT NOT NULL,\n",
    "        country TEXT NOT NULL,\n",
    "        temperature_max REAL,\n",
    "        extreme REAL\n",
    "    );\n",
    "''')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9809f627-b3d3-4bef-a7a9-1c9e4cd82a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keep Necessary Columns\n",
    "weather_table = weather_df[['date', 'company', 'country', 'temperature_max', 'extreme']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3976df82-720c-4997-aead-636e876be070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert the data from the DataFrame into the WeatherData table\n",
    "weather_table.to_sql('WeatherData', con, if_exists='append', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ea29492-e1ef-499c-95f8-1091af39f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Commit the transaction\n",
    "con.commit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed01f2bb-3bd3-4ab6-8ba9-25de5913223a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verify the data by querying the WeatherData table\n",
    "query_result_weatherdata = pd.read_sql_query(\"SELECT * FROM WeatherData\", con)\n",
    "print(query_result_weatherdata)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c304df0-662e-4077-8d31-76d6236d20f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Summary Stats of this Table\n",
    "\n",
    "# Define the columns you want to analyse\n",
    "columns_to_analyse2 = ['temperature_max', 'extreme']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af921a21-d167-41f9-821c-7384eb3767b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list to store results\n",
    "weatherdata_analysis = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f27dd2-a2ec-41a1-bc87-623b84332f17",
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in columns_to_analyse2:\n",
    "    query = f\"\"\"\n",
    "    SELECT\n",
    "        '{column}' AS column_name,\n",
    "        AVG({column}) AS mean,\n",
    "        MIN({column}) AS min,\n",
    "        MAX({column}) AS max,\n",
    "        SUM({column}) AS sum,\n",
    "        AVG({column} * {column}) - AVG({column}) * AVG({column}) AS variance\n",
    "    FROM WeatherData\n",
    "    WHERE {column} IS NOT NULL\n",
    "    \"\"\"\n",
    "\n",
    "    df4 = pd.read_sql_query(query, con)\n",
    "    df4['std_dev'] = np.sqrt(df4['variance'])\n",
    "    weatherdata_analysis.append(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d92c8ec1-4364-4f21-8fb1-6b1d960871f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all results\n",
    "weatherdata_results = pd.concat(weatherdata_analysis, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7625c881-bde9-4ec0-b1f7-186631340172",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the results\n",
    "print(weatherdata_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e576456-7ade-429d-81e5-01f508106f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Close the database connection\n",
    "con.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8fbf0c1-4603-4830-b568-69e3fc4d9491",
   "metadata": {},
   "source": [
    "########### SUMMARY STATISTICS OF RETURNS ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aee4266-1ecd-439a-b6c1-76b9e98cd701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Summary of the full dataset\n",
    "monthly_returns['returns'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd3a1a1b-860f-4a0d-8ffb-febb9837ef87",
   "metadata": {},
   "source": [
    "####### Add country column to monthly_returns to be able to sort by country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cfb85b-0286-4a65-a88d-029d9dd8df49",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming weather_data has 'country' and 'company' columns\n",
    "company_country_map = weather_df[['company', 'country']].drop_duplicates().set_index('company')['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e0bad6-024d-4f1f-a073-685205f7ab2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the country column to monthly_returns\n",
    "monthly_returns['country'] = monthly_returns['company'].map(company_country_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fba92393-c073-485a-98b8-789c1f62f999",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This shows the dataframe with the country column\n",
    "monthly_returns.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "724cc359-3e1f-41fc-967d-b435bbab5e21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the low-risk countries\n",
    "low_risk_countries = ['Japan', 'South Korea', 'Singapore']\n",
    "\n",
    "# Create the low_risk DataFrame\n",
    "low_risk = monthly_returns[monthly_returns['country'].isin(low_risk_countries)][['date', 'company', 'country', 'returns']]\n",
    "\n",
    "# Create the high_risk DataFrame\n",
    "high_risk = monthly_returns[~monthly_returns['country'].isin(low_risk_countries)][['date', 'company', 'country', 'returns']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80b46f6-c91b-4279-aade-827b89a63d47",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of each DataFrame\n",
    "print(\"High Risk DataFrame:\")\n",
    "print(high_risk.head())\n",
    "\n",
    "print(\"\\nLow Risk DataFrame:\")\n",
    "print(low_risk.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "478993a7-9c45-4ea6-b146-f8496ae2b9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# HIGH\n",
    "\n",
    "print(\"High Risk Summary:\")\n",
    "print(high_risk['returns'].describe())\n",
    "\n",
    "print(\"\\nHigh Risk Skewness:\")\n",
    "print(high_risk['returns'].skew())\n",
    "\n",
    "print(\"\\nHigh Risk Kurtosis:\")\n",
    "print(high_risk['returns'].kurt())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c47a8303-87f3-424d-87f9-f71aa38a1332",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LOW\n",
    "\n",
    "print(\"Low Risk Summary:\")\n",
    "print(low_risk['returns'].describe())\n",
    "\n",
    "print(\"\\nLow Risk Skewness:\")\n",
    "print(low_risk['returns'].skew())\n",
    "\n",
    "print(\"\\nLow Risk Kurtosis:\")\n",
    "print(low_risk['returns'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27fb45da-38cc-4680-a775-e22f4d72e314",
   "metadata": {},
   "source": [
    "####### Visualisation of returns volatility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6156df0-7094-424b-ae9f-3d2602445ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2959082a-40c2-4ed4-a074-49d1db579f9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "high_risk = high_risk.sort_values('date')\n",
    "low_risk = low_risk.sort_values('date')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a762a5fd-3d73-4b03-973a-25898ce7bac2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.scatter(high_risk['date'], high_risk['returns'], label='High-Risk', color='red', alpha=0.5, s=10)\n",
    "plt.scatter(low_risk['date'], low_risk['returns'], label='Low-Risk', color='green', alpha=0.5, s=10)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Returns')\n",
    "plt.title('Comparison of Log Returns')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "plt.gcf().autofmt_xdate(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5f8ec-a9cd-43c7-914d-338bd9241eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(high_risk['date'], high_risk['returns'], label='High-Risk', color='red', linestyle=':', marker='.', markersize=2)\n",
    "plt.plot(low_risk['date'], low_risk['returns'], label='Low-Risk', color='green', linestyle=':', marker='.', markersize=2)\n",
    "\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Returns')\n",
    "plt.title('Comparison of Log Returns')\n",
    "plt.legend()\n",
    "plt.grid(True, alpha=0.3)\n",
    "\n",
    "ax = plt.gca()\n",
    "ax.xaxis.set_major_locator(mdates.YearLocator())\n",
    "ax.xaxis.set_major_formatter(mdates.DateFormatter('%Y'))\n",
    "\n",
    "plt.gcf().autofmt_xdate(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33038d82-adf2-4eed-bf42-9d8dcdf81074",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine the two DataFrame's log returns\n",
    "combined_data = pd.concat([monthly_returns['date'], high_risk['returns'], low_risk['returns']], axis=1)\n",
    "combined_data.columns = ['date', 'high_risk_returns', 'low_risk_returns']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bc0b922-fee5-4309-8213-7fb9a0f0989b",
   "metadata": {},
   "source": [
    "####### Visualisation of the distribution of returns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2387170-2dff-4e15-8eee-c8721fa1a115",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the KDE plot\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.kdeplot(data=high_risk['returns'], label='High Risk', color='red', shade=True)\n",
    "sns.kdeplot(data=low_risk['returns'], label='Low Risk', color='green', shade=True)\n",
    "\n",
    "# Styling improvements\n",
    "plt.title('Distribution of Returns: Risk Comparison', fontsize=16, fontweight='bold')\n",
    "plt.xlabel('Returns', fontsize=12)\n",
    "plt.ylabel('Density', fontsize=12)\n",
    "plt.grid(True, linestyle='--', linewidth=0.5, alpha=0.7)\n",
    "plt.legend(shadow=True, frameon=True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "744f1dec-8758-4443-85dd-7b422be759d1",
   "metadata": {},
   "source": [
    "########### PREPARATION OF REGRESSION DATA ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c7b9a7c-ba01-4380-9781-2aa1ee781d8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare annual_financials for merging\n",
    "annual_financials['date'] = pd.to_datetime(annual_financials['date'])\n",
    "annual_financials['year'] = annual_financials['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6aded40-c9d6-4076-8beb-8db36520623d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a date range for each year in annual_financials\n",
    "date_ranges = annual_financials.apply(lambda row: pd.date_range(start=f\"{row['year']}-01-01\", end=f\"{row['year']}-12-31\", freq='M'), axis=1)\n",
    "annual_financials_expanded = annual_financials.loc[annual_financials.index.repeat(date_ranges.str.len())].reset_index(drop=True)\n",
    "annual_financials_expanded['date'] = [date for dates in date_ranges for date in dates]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb42bab-acd8-42bf-8548-e4d69efc97f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge annual_financials_expanded with monthly_returns\n",
    "regression_data = pd.merge(monthly_returns[['date', 'year', 'company', 'returns']], \n",
    "                           annual_financials_expanded[['date', 'year', 'company', 'financial_leverage', 'market_capitalisation']], \n",
    "                           on=['date', 'year', 'company'], \n",
    "                           how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb6b2b-8a74-4248-9be0-87f7b29ebecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge with extreme_days_df\n",
    "regression_data = pd.merge(regression_data, \n",
    "                           extreme_days_df[['year', 'month', 'company', 'extreme_days']], \n",
    "                           left_on=['year', regression_data['date'].dt.month, 'company'], \n",
    "                           right_on=['year', 'month', 'company'], \n",
    "                           how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea9fdddf-e215-43bc-942f-85b12b1a1b1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop unnecessary columns and reorder\n",
    "regression_data = regression_data[['date', 'year', 'company', 'returns', 'extreme_days', 'financial_leverage', 'market_capitalisation']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8179f73a-d135-4fea-8eee-58f42c26166b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows of the new DataFrame\n",
    "print(regression_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba6ca971-e289-46dc-8c85-aa834a77fe05",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'country' column\n",
    "company_country_map1 = weather_df[['company', 'country']].drop_duplicates().set_index('company')['country']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d17dab89-9032-4b51-8781-f460b31febcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the 'country' column to monthly_returns\n",
    "regression_data['country'] = regression_data['company'].map(company_country_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2f61b6-5add-4d93-890c-fde8b0e0f78a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(regression_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ccf83dc-d4da-47ba-b1c2-b071e549f279",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define high-risk countries\n",
    "low_risk_countries = ['Japan', 'South Korea', 'Singapore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a646c11-e118-4281-86b3-19bf5953a92e",
   "metadata": {},
   "outputs": [],
   "source": [
    "regression_data1 = regression_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4888d73-4969-44d8-89ff-a67f90cdf94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'risk_class' column\n",
    "regression_data1['risk_class'] = np.where(regression_data['country'].isin(low_risk_countries), 1, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013e85a2-b5fe-43cd-8bf6-593ce72490cb",
   "metadata": {},
   "source": [
    "########### REGRESSION ANALYSIS ###########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7eceeb7-a405-4823-bac5-1db3ccbc2701",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "import statsmodels.api as sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26fc68a1-ef6c-4e78-9b44-a44849bdec51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the 'interaction_term' column\n",
    "regression_data1['risk_extreme_interaction'] = regression_data1['risk_class'] * regression_data1['extreme_days']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd32ca7a-1dfa-44ce-ae67-a5a242d67bc4",
   "metadata": {},
   "source": [
    "####### MIX STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eda07e3-9e5e-4389-9934-6dbd30edb46f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the data\n",
    "X = regression_data1[['extreme_days', 'risk_class', 'risk_extreme_interaction', 'market_capitalisation', 'financial_leverage']]\n",
    "y = regression_data1['returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4047baed-e695-470c-bbc7-b1611ca670d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN and infinite values\n",
    "X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y = y[X.index]  # Align y with X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f44942-359b-416e-9bba-676654ffefa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make them all floats\n",
    "X = X.astype(float)\n",
    "y = y.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d497bc7-67a4-495b-a3d5-61c0f241753b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant term to the independent variables\n",
    "X = sm.add_constant(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63795090-be29-4579-bf2c-a6f77291580c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the regression model\n",
    "model = sm.OLS(y, X).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6cdbd00-b4eb-4a0e-9457-589a8a0235a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary of the regression\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7adc8bb8-a97a-4d2e-878b-9d039711a927",
   "metadata": {},
   "source": [
    "####### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75a6d831-5c31-45df-98f6-cc2dac4bf148",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(regression_data1['extreme_days'], regression_data1['returns'], color='blue', alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Extreme Days')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('Correlation between Extreme Days and Returns')\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be4710ee-7298-4cb0-89a7-98314b2f59a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(regression_data1['risk_extreme_interaction'], regression_data1['returns'], color='blue', alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Risk Class & Extreme Days Interaction')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('Correlation between Interaction Term and Returns')\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9d31994-339a-4727-9b77-7458452efd92",
   "metadata": {},
   "source": [
    "####### LOW RISK STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0a24ef-6e29-4a92-9863-6a68c3349d54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define high-risk countries\n",
    "low_risk_countries = ['Japan', 'South Korea', 'Singapore']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d536a665-e045-4713-b24b-e0e0c10a1c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'regression_data_low' DataFrame\n",
    "regression_data_low = regression_data[regression_data['country'].isin(low_risk_countries)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3888d8bd-8ff4-4d06-be8c-81653672d00b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the new DataFrame\n",
    "regression_data_low.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46447c9f-6232-40b0-9b89-0f23513fdd82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows and info of the new DataFrame\n",
    "print(regression_data_low.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(regression_data_low.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41528ec9-c27c-410d-a0a1-83abdc3b0c91",
   "metadata": {},
   "outputs": [],
   "source": [
    "X1 = regression_data_low[['extreme_days', 'financial_leverage', 'market_capitalisation']]\n",
    "y1 = regression_data_low['returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ede3ed40-0307-4de1-bbf5-eb608f56453d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN and infinite values\n",
    "X1 = X1.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y1 = y1[X1.index]  # Align y with X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aae888-a469-43af-93db-fa8637961d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make them all floats\n",
    "X1 = X1.astype(float)\n",
    "y1 = y1.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f888b2d9-5380-4230-a04d-2e95546e555a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant term to the independent variables\n",
    "X1 = sm.add_constant(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c53c1c-673e-4c1b-8e73-f46841b9d2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the regression model\n",
    "low_model = sm.OLS(y1, X1).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd9a497-06ea-4a30-8923-5a6c4c04f1b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary of the regression\n",
    "print(low_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a12fc5-53e2-4c10-8233-8e9265488532",
   "metadata": {},
   "source": [
    "####### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfa28f30-5699-4dad-a9f9-b725a1982068",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(regression_data_low['extreme_days'], regression_data_low['returns'], color='blue', alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Extreme Days')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('Correlation between Extreme Days and Returns')\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cc93b3-33e1-45b1-b46a-690020901416",
   "metadata": {},
   "source": [
    "####### HIGH RISK STUDY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4aa280d-44f9-4a83-84aa-8bb127708251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 'regression_data_high' DataFrame\n",
    "regression_data_high = regression_data[~regression_data['country'].isin(low_risk_countries)].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42fc0651-135d-4d14-aa90-e41ee73cba25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index of the new DataFrame\n",
    "regression_data_high.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b70518-085f-41c5-b705-cdc9de6749bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display the first few rows and info of the new DataFrame\n",
    "print(regression_data_high.head())\n",
    "print(\"\\nDataFrame Info:\")\n",
    "print(regression_data_high.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd377cd-1ca0-4de3-8fb2-c908c87932eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = regression_data_high[['extreme_days', 'financial_leverage', 'market_capitalisation']]\n",
    "y2 = regression_data_high['returns']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9dbdce2d-56a8-4aa8-b1fc-45d28bd7fd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove NaN and infinite values\n",
    "X2 = X2.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "y2 = y2[X2.index]  # Align y with X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40294568-1878-4f62-a54d-2aecee154e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make them all floats\n",
    "X2 = X2.astype(float)\n",
    "y2 = y2.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ead5676-6e52-4874-ab5a-7899b3958b73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add a constant term to the independent variables\n",
    "X2 = sm.add_constant(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3595a-57be-49ae-bb61-8aea68d20586",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the regression model\n",
    "high_model = sm.OLS(y2, X2).fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67ae659f-aacc-4e3e-8dc7-46a7477640ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the summary of the regression\n",
    "print(high_model.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11c746a8-3b11-468f-8f0f-bd0d4df9191e",
   "metadata": {},
   "source": [
    "####### Visualisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c4fde7-df75-401e-8334-df16f4b67a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(regression_data_high['extreme_days'], regression_data_high['returns'], color='blue', alpha=0.6)\n",
    "\n",
    "# Add labels and title\n",
    "plt.xlabel('Extreme Days')\n",
    "plt.ylabel('Returns')\n",
    "plt.title('Correlation between Extreme Days and Returns')\n",
    "\n",
    "# Display the plot\n",
    "plt.grid(True, linestyle='--', alpha=0.7)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
